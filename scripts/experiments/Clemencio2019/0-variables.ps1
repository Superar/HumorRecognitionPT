# Corpus
$ORIGINAL_CORPUS_PATH = '.\data\Humor\Datasets\Balanceados\all.txt'
$JSON_CORPUS_PATH = '.\data\Humor\Datasets\Balanceados\all.json'

# Preprocessing
$PREPROCESSED_CORPUS_PATH = '.\data\Humor\preprocessed\all.json'

# Split
$SPLIT_CORPUS_PATH = '.\data\Humor\split\all'

# Features
$CONTENT_FEATURES_PATH = '.\data\Humor\features\all_content_features'
$HUMOR_FEATURES_PATH = '.\data\Humor\features\all_humor_features'
$ALL_FEATURES_PATH = '.\data\Humor\features\all_all_features'

# Resources
$SENTLEX = '.\data\Lexica\SentiLex02.json'
$SLANG = '.\data\Lexica\termos_calao.json'
$ANTONYM_TRIPLES = '.\data\Lexica\antonyms.json'
$EMBEDDINGS = '.\data\Lexica\cbow_s300.txt'
$MWP = '.\data\Lexica\MWP.json'

# Classification models
$CONTENT_FEATURES_MODELS = '.\results\models\all_content_features'
$HUMOR_FEATURES_MODELS = '.\results\models\all_humor_features'
$ALL_FEATURES_MODELS = '.\results\models\all_all_features'

# Test predictions
$CONTENT_FEATURES_PREDICTIONS = '.\results\predictions\all_content_features'
$HUMOR_FEATURES_PREDICTIONS = '.\results\predictions\all_humor_features'
$ALL_FEATURES_PREDICTIONS = '.\results\predictions\all_all_features'
